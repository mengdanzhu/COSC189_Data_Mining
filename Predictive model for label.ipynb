{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data\n",
    "final_vote=pd.read_csv('clean_vote_vect.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>vote</th>\n",
       "      <th>help</th>\n",
       "      <th>recommend</th>\n",
       "      <th>helpful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>refin gameplay layer mechan top tradit clicker...</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>14 people found this review helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>complaint review game truli idl want write rev...</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>9 people found this review helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clicker game time manag idl game pro great sou...</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>7 people found this review helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>play game year kept consist interest time freq...</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>26 people found this review helpful4 people fo...</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>play idl clicker increment game year definit s...</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>10 people found this review helpful</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text         vote  \\\n",
       "0  refin gameplay layer mechan top tradit clicker...  Recommended   \n",
       "1  complaint review game truli idl want write rev...  Recommended   \n",
       "2  clicker game time manag idl game pro great sou...  Recommended   \n",
       "3  play game year kept consist interest time freq...  Recommended   \n",
       "4  play idl clicker increment game year definit s...  Recommended   \n",
       "\n",
       "                                                help  recommend  helpful  \\\n",
       "0                14 people found this review helpful          1     14.0   \n",
       "1                 9 people found this review helpful          1      9.0   \n",
       "2                 7 people found this review helpful          1      7.0   \n",
       "3  26 people found this review helpful4 people fo...          1     26.0   \n",
       "4                10 people found this review helpful          1     10.0   \n",
       "\n",
       "   funny  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  \n",
       "3    4.0  \n",
       "4    NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vote.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split training and testing\n",
    "X_train,X_test,y_train,y_test=train_test_split(final_vote['text'],\n",
    "                                              final_vote['recommend'],\n",
    "                                              test_size=0.25,\n",
    "                                              random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set type\n",
    "X_train=X_train.values.astype('U')\n",
    "X_test=X_test.values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3 gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-gram\n",
    "vect=CountVectorizer(ngram_range=(1,1),min_df=5).fit(X_train)\n",
    "vect_name=vect.get_feature_names()\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "full_text_matrix=vect.transform(final_vote['text'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-gram\n",
    "vect_bigram=CountVectorizer(ngram_range=(1,2),min_df=5).fit(X_train)\n",
    "X_train_bivectorized = vect_bigram.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-gram\n",
    "vect_trigram=CountVectorizer(ngram_range=(1,3),min_df=5).fit(X_train)\n",
    "X_train_trivectorized = vect_trigram.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaand</th>\n",
       "      <th>aaand</th>\n",
       "      <th>aand</th>\n",
       "      <th>aard</th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandonwar</th>\n",
       "      <th>...</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zombifi</th>\n",
       "      <th>zomboid</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>ztd</th>\n",
       "      <th>zu</th>\n",
       "      <th>zula</th>\n",
       "      <th>zweihand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 16100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aaa  aaaand  aaand  aand  aard  ab  aback  abandon  abandonwar  ...  \\\n",
       "0   0    0       0      0     0     0   0      0        0           0  ...   \n",
       "1   0    0       0      0     0     0   0      0        0           0  ...   \n",
       "2   0    0       0      0     0     0   0      0        0           0  ...   \n",
       "3   0    0       0      0     0     0   0      0        0           0  ...   \n",
       "4   0    0       0      0     0     0   0      0        0           0  ...   \n",
       "\n",
       "   zombi  zombifi  zomboid  zone  zoo  zoom  ztd  zu  zula  zweihand  \n",
       "0      0        0        0     0    0     0    0   0     0         0  \n",
       "1      0        0        0     0    0     0    0   0     0         0  \n",
       "2      0        0        0     0    0     0    0   0     0         0  \n",
       "3      0        0        0     0    0     0    0   0     0         0  \n",
       "4      0        0        0     0    0     0    0   0     0         0  \n",
       "\n",
       "[5 rows x 16100 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sparce matrix\n",
    "text_vector=pd.DataFrame(full_text_matrix.toarray(),columns=vect.get_feature_names())\n",
    "text_vector.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_vectorized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aef70f689135>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 1-gram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_vectorized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mscore_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 2-gram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_vectorized' is not defined"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# 1-gram\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "score_pred = model.predict(vect.transform(X_test))\n",
    "# 2-gram\n",
    "model_bigram=LogisticRegression()\n",
    "model_bigram.fit(X_train_bivectorized,y_train)\n",
    "predictions_bigram=model_bigram.predict(vect_bigram.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-gram\n",
    "model_trigram=LogisticRegression()\n",
    "model_trigram.fit(X_train_trivectorized,y_train)\n",
    "predictions_trigram=model_trigram.predict(vect_trigram.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3852   825]\n",
      " [ 2262 18529]]\n",
      "0.9231037489102005\n",
      "0.8787890686351499\n",
      "[[ 4347   826]\n",
      " [ 1767 18528]]\n",
      "0.9346011248707408\n",
      "0.8981859588503219\n",
      "[[ 4338   838]\n",
      " [ 1776 18516]]\n",
      "0.9340664884225395\n",
      "0.8973613946913774\n"
     ]
    }
   ],
   "source": [
    "#results for logstic regression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,f1_score\n",
    "# 1-gram\n",
    "print(confusion_matrix(score_pred,y_test))\n",
    "print(f1_score(score_pred,y_test))\n",
    "print(accuracy_score(score_pred,y_test))\n",
    "# 2-gram\n",
    "print(confusion_matrix(predictions_bigram,y_test))\n",
    "print(f1_score(predictions_bigram,y_test))\n",
    "print(accuracy_score(predictions_bigram,y_test))\n",
    "# 3-gram\n",
    "print(confusion_matrix(predictions_trigram,y_test))\n",
    "print(f1_score(predictions_trigram,y_test))\n",
    "print(accuracy_score(predictions_trigram,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': range(1, 10),\n",
       "                         'n_estimators': range(10, 100, 10)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {'n_estimators': range(10,100,10), 'max_depth': range(1,10)}\n",
    "\n",
    "gscv=GridSearchCV(RandomForestClassifier(),param_grid,scoring= 'accuracy',cv=10)\n",
    "gscv.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal parameters: \n",
      "max_depth:9 n_estimators:10\n",
      "0.7584518932502651\n"
     ]
    }
   ],
   "source": [
    "print(\"The optimal parameters: \\nmax_depth:{} n_estimators:{}\".\n",
    "      format(gscv.best_params_[\"max_depth\"],gscv.best_params_[\"n_estimators\"]))\n",
    "print(gscv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-gram\n",
    "rf1_model = RandomForestClassifier(max_depth=gscv.best_params_[\"max_depth\"],\n",
    "                                   n_estimators=gscv.best_params_[\"n_estimators\"])\n",
    "rf1_model.fit(X_train_vectorized, y_train)\n",
    "rf1_predict=rf1_model.predict(vect.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   68     8]\n",
      " [ 6046 19346]]\n",
      "0.8647029902114156\n",
      "0.7622899324642689\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(rf1_predict,y_test))\n",
    "print(f1_score(rf1_predict,y_test))\n",
    "print(accuracy_score(rf1_predict,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-gram\n",
    "rf2_model = RandomForestClassifier(max_depth=gscv.best_params_[\"max_depth\"],\n",
    "                                   n_estimators=gscv.best_params_[\"n_estimators\"])\n",
    "rf2_model.fit(X_train_bivectorized, y_train)\n",
    "rf2_predict=rf2_model.predict(vect_bigram.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    4     1]\n",
      " [ 6110 19353]]\n",
      "0.8636454916661087\n",
      "0.7600518297471337\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(rf2_predict,y_test))\n",
    "print(f1_score(rf2_predict,y_test))\n",
    "print(accuracy_score(rf2_predict,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-gram\n",
    "rf3_model = RandomForestClassifier(max_depth=gscv.best_params_[\"max_depth\"],\n",
    "                                   n_estimators=gscv.best_params_[\"n_estimators\"])\n",
    "rf3_model.fit(X_train_trivectorized, y_train)\n",
    "rf3_predict=rf3_model.predict(vect_trigram.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    3     1]\n",
      " [ 6111 19353]]\n",
      "0.8636262216073898\n",
      "0.7600125647871839\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(rf3_predict,y_test))\n",
    "print(f1_score(rf3_predict,y_test))\n",
    "print(accuracy_score(rf3_predict,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-gram\n",
    "svm1 = svm.SVC(gamma='scale')\n",
    "svm1.fit(X_train_vectorized, y_train)\n",
    "svm1_predict=svm1.predict(vect.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3142   489]\n",
      " [ 2972 18865]]\n",
      "0.9159767910465879\n",
      "0.8641039736139469\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(svm1_predict,y_test))\n",
    "print(f1_score(svm1_predict,y_test))\n",
    "print(accuracy_score(svm1_predict,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-gram\n",
    "svm2 = svm.SVC(gamma='scale')\n",
    "svm2.fit(X_train_bivectorized, y_train)\n",
    "svm2_predict=svm2.predict(vect_bigram.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3172   447]\n",
      " [ 2942 18907]]\n",
      "0.9177487076183772\n",
      "0.8669310507303283\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(svm2_predict,y_test))\n",
    "print(f1_score(svm2_predict,y_test))\n",
    "print(accuracy_score(svm2_predict,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-gram\n",
    "svm3 = svm.SVC(gamma='scale')\n",
    "svm3.fit(X_train_trivectorized, y_train)\n",
    "svm3_predict=svm3.predict(vect_trigram.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3172   448]\n",
      " [ 2942 18906]]\n",
      "0.9177224406582204\n",
      "0.8668917857703785\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(svm3_predict,y_test))\n",
    "print(f1_score(svm3_predict,y_test))\n",
    "print(accuracy_score(svm3_predict,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
